{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 4400 Final Project : Credit Card Fraud Detection\n",
    "\n",
    "#### Emily Chen, Glen Damian Lim, Tara Sawhney\n",
    "\n",
    "#### Dataset : https://www.kaggle.com/datasets/kartik2112/fraud-detection\n",
    "\n",
    "#### ML models: Logistic Regression, Decision Trees, Feedforward Neural Networks, Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# ML libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "# Neural Networks libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('fraudTrain.csv')\n",
    "df_test = pd.read_csv('fraudTest.csv')\n",
    "# df_train.drop_duplicates(inplace=True)\n",
    "# df_test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>1296670</td>\n",
       "      <td>2020-06-21 12:12:08</td>\n",
       "      <td>30263540414123</td>\n",
       "      <td>fraud_Reichel Inc</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>15.56</td>\n",
       "      <td>Erik</td>\n",
       "      <td>Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>162 Jessica Row Apt. 072</td>\n",
       "      <td>...</td>\n",
       "      <td>37.7175</td>\n",
       "      <td>-112.4777</td>\n",
       "      <td>258</td>\n",
       "      <td>Geoscientist</td>\n",
       "      <td>1961-11-24</td>\n",
       "      <td>440b587732da4dc1a6395aba5fb41669</td>\n",
       "      <td>1371816728</td>\n",
       "      <td>36.841266</td>\n",
       "      <td>-111.690765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>1296671</td>\n",
       "      <td>2020-06-21 12:12:19</td>\n",
       "      <td>6011149206456997</td>\n",
       "      <td>fraud_Abernathy and Sons</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>51.70</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>8617 Holmes Terrace Suite 651</td>\n",
       "      <td>...</td>\n",
       "      <td>39.2667</td>\n",
       "      <td>-77.5101</td>\n",
       "      <td>100</td>\n",
       "      <td>Production assistant, television</td>\n",
       "      <td>1979-12-11</td>\n",
       "      <td>278000d2e0d2277d1de2f890067dcc0a</td>\n",
       "      <td>1371816739</td>\n",
       "      <td>38.906881</td>\n",
       "      <td>-78.246528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>1296672</td>\n",
       "      <td>2020-06-21 12:12:32</td>\n",
       "      <td>3514865930894695</td>\n",
       "      <td>fraud_Stiedemann Ltd</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>105.93</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Castaneda</td>\n",
       "      <td>M</td>\n",
       "      <td>1632 Cohen Drive Suite 639</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9396</td>\n",
       "      <td>-105.8189</td>\n",
       "      <td>899</td>\n",
       "      <td>Naval architect</td>\n",
       "      <td>1967-08-30</td>\n",
       "      <td>483f52fe67fabef353d552c1e662974c</td>\n",
       "      <td>1371816752</td>\n",
       "      <td>33.619513</td>\n",
       "      <td>-105.130529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>1296673</td>\n",
       "      <td>2020-06-21 12:13:36</td>\n",
       "      <td>2720012583106919</td>\n",
       "      <td>fraud_Reinger, Weissnat and Strosin</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>74.90</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Murray</td>\n",
       "      <td>M</td>\n",
       "      <td>42933 Ryan Underpass</td>\n",
       "      <td>...</td>\n",
       "      <td>43.3526</td>\n",
       "      <td>-102.5411</td>\n",
       "      <td>1126</td>\n",
       "      <td>Volunteer coordinator</td>\n",
       "      <td>1980-08-18</td>\n",
       "      <td>d667cdcbadaaed3da3f4020e83591c83</td>\n",
       "      <td>1371816816</td>\n",
       "      <td>42.788940</td>\n",
       "      <td>-103.241160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>1296674</td>\n",
       "      <td>2020-06-21 12:13:37</td>\n",
       "      <td>4292902571056973207</td>\n",
       "      <td>fraud_Langosh, Wintheiser and Hyatt</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>135 Joseph Mountains</td>\n",
       "      <td>...</td>\n",
       "      <td>45.8433</td>\n",
       "      <td>-113.8748</td>\n",
       "      <td>218</td>\n",
       "      <td>Therapist, horticultural</td>\n",
       "      <td>1995-08-16</td>\n",
       "      <td>8f7c8e4ab7f25875d753b422917c98c9</td>\n",
       "      <td>1371816817</td>\n",
       "      <td>46.565983</td>\n",
       "      <td>-114.186110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 trans_date_trans_time               cc_num  \\\n",
       "0                 0   2019-01-01 00:00:18     2703186189652095   \n",
       "1                 1   2019-01-01 00:00:44         630423337322   \n",
       "2                 2   2019-01-01 00:00:51       38859492057661   \n",
       "3                 3   2019-01-01 00:01:16     3534093764340240   \n",
       "4                 4   2019-01-01 00:03:06      375534208663984   \n",
       "...             ...                   ...                  ...   \n",
       "1296670     1296670   2020-06-21 12:12:08       30263540414123   \n",
       "1296671     1296671   2020-06-21 12:12:19     6011149206456997   \n",
       "1296672     1296672   2020-06-21 12:12:32     3514865930894695   \n",
       "1296673     1296673   2020-06-21 12:13:36     2720012583106919   \n",
       "1296674     1296674   2020-06-21 12:13:37  4292902571056973207   \n",
       "\n",
       "                                    merchant       category     amt  \\\n",
       "0                 fraud_Rippin, Kub and Mann       misc_net    4.97   \n",
       "1            fraud_Heller, Gutmann and Zieme    grocery_pos  107.23   \n",
       "2                       fraud_Lind-Buckridge  entertainment  220.11   \n",
       "3         fraud_Kutch, Hermiston and Farrell  gas_transport   45.00   \n",
       "4                        fraud_Keeling-Crist       misc_pos   41.96   \n",
       "...                                      ...            ...     ...   \n",
       "1296670                    fraud_Reichel Inc  entertainment   15.56   \n",
       "1296671             fraud_Abernathy and Sons    food_dining   51.70   \n",
       "1296672                 fraud_Stiedemann Ltd    food_dining  105.93   \n",
       "1296673  fraud_Reinger, Weissnat and Strosin    food_dining   74.90   \n",
       "1296674  fraud_Langosh, Wintheiser and Hyatt    food_dining    4.30   \n",
       "\n",
       "               first       last gender                         street  ...  \\\n",
       "0           Jennifer      Banks      F                 561 Perry Cove  ...   \n",
       "1          Stephanie       Gill      F   43039 Riley Greens Suite 393  ...   \n",
       "2             Edward    Sanchez      M       594 White Dale Suite 530  ...   \n",
       "3             Jeremy      White      M    9443 Cynthia Court Apt. 038  ...   \n",
       "4              Tyler     Garcia      M               408 Bradley Rest  ...   \n",
       "...              ...        ...    ...                            ...  ...   \n",
       "1296670         Erik  Patterson      M       162 Jessica Row Apt. 072  ...   \n",
       "1296671      Jeffrey      White      M  8617 Holmes Terrace Suite 651  ...   \n",
       "1296672  Christopher  Castaneda      M     1632 Cohen Drive Suite 639  ...   \n",
       "1296673       Joseph     Murray      M           42933 Ryan Underpass  ...   \n",
       "1296674      Jeffrey      Smith      M           135 Joseph Mountains  ...   \n",
       "\n",
       "             lat      long  city_pop                                job  \\\n",
       "0        36.0788  -81.1781      3495          Psychologist, counselling   \n",
       "1        48.8878 -118.2105       149  Special educational needs teacher   \n",
       "2        42.1808 -112.2620      4154        Nature conservation officer   \n",
       "3        46.2306 -112.1138      1939                    Patent attorney   \n",
       "4        38.4207  -79.4629        99     Dance movement psychotherapist   \n",
       "...          ...       ...       ...                                ...   \n",
       "1296670  37.7175 -112.4777       258                       Geoscientist   \n",
       "1296671  39.2667  -77.5101       100   Production assistant, television   \n",
       "1296672  32.9396 -105.8189       899                    Naval architect   \n",
       "1296673  43.3526 -102.5411      1126              Volunteer coordinator   \n",
       "1296674  45.8433 -113.8748       218           Therapist, horticultural   \n",
       "\n",
       "                dob                         trans_num   unix_time  merch_lat  \\\n",
       "0        1988-03-09  0b242abb623afc578575680df30655b9  1325376018  36.011293   \n",
       "1        1978-06-21  1f76529f8574734946361c461b024d99  1325376044  49.159047   \n",
       "2        1962-01-19  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704   \n",
       "3        1967-01-12  6b849c168bdad6f867558c3793159a81  1325376076  47.034331   \n",
       "4        1986-03-28  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999   \n",
       "...             ...                               ...         ...        ...   \n",
       "1296670  1961-11-24  440b587732da4dc1a6395aba5fb41669  1371816728  36.841266   \n",
       "1296671  1979-12-11  278000d2e0d2277d1de2f890067dcc0a  1371816739  38.906881   \n",
       "1296672  1967-08-30  483f52fe67fabef353d552c1e662974c  1371816752  33.619513   \n",
       "1296673  1980-08-18  d667cdcbadaaed3da3f4020e83591c83  1371816816  42.788940   \n",
       "1296674  1995-08-16  8f7c8e4ab7f25875d753b422917c98c9  1371816817  46.565983   \n",
       "\n",
       "         merch_long  is_fraud  \n",
       "0        -82.048315         0  \n",
       "1       -118.186462         0  \n",
       "2       -112.154481         0  \n",
       "3       -112.561071         0  \n",
       "4        -78.632459         0  \n",
       "...             ...       ...  \n",
       "1296670 -111.690765         0  \n",
       "1296671  -78.246528         0  \n",
       "1296672 -105.130529         0  \n",
       "1296673 -103.241160         0  \n",
       "1296674 -114.186110         0  \n",
       "\n",
       "[1296675 rows x 23 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_column(df, col_name: str, hour: bool =False, new_col_prefix: str =''):\n",
    "    df[col_name] = pd.to_datetime(df[col_name])\n",
    "\n",
    "    if hour:\n",
    "        new_col = new_col_prefix + '_hour'\n",
    "        df[new_col] = df[col_name].dt.hour\n",
    "    df[new_col_prefix + '_weekday'] = df[col_name].dt.weekday\n",
    "    df[new_col_prefix + '_month'] = df[col_name].dt.strftime(\"%m\")\n",
    "    df[new_col_prefix + '_year'] = df[col_name].dt.year\n",
    "\n",
    "# deriving additonal columns from 'trans_date_trans_time' and 'dob' columns\n",
    "# datetime_column(df_train, 'trans_date_trans_time', True, 'trans')\n",
    "# datetime_column(df_test, 'trans_date_trans_time', True, 'trans')\n",
    "# datetime_column(df_train, 'dob', new_col_prefix='dob')\n",
    "# datetime_column(df_test, 'dob', new_col_prefix='dob')\n",
    "\n",
    "\n",
    "# dropping irrelevant columns\n",
    "# df_train.drop(['Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "# df_test.drop(['Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "df_train.drop(['gender','city','state','job','unix_time','Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "df_test.drop(['gender','city','state','job','unix_time','Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "# Convert categorical columns\n",
    "# categorical_column_names = ['city', 'state', 'job', 'category']\n",
    "# categorical_column_names = ['category']\n",
    "\n",
    "# for cat_name in categorical_column_names:\n",
    "#     df_train[cat_name] = pd.factorize(df_train[cat_name])[0]\n",
    "#     df_test[cat_name] = pd.factorize(df_test[cat_name])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>15.56</td>\n",
       "      <td>37.7175</td>\n",
       "      <td>-112.4777</td>\n",
       "      <td>258</td>\n",
       "      <td>36.841266</td>\n",
       "      <td>-111.690765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>food_dining</td>\n",
       "      <td>51.70</td>\n",
       "      <td>39.2667</td>\n",
       "      <td>-77.5101</td>\n",
       "      <td>100</td>\n",
       "      <td>38.906881</td>\n",
       "      <td>-78.246528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>food_dining</td>\n",
       "      <td>105.93</td>\n",
       "      <td>32.9396</td>\n",
       "      <td>-105.8189</td>\n",
       "      <td>899</td>\n",
       "      <td>33.619513</td>\n",
       "      <td>-105.130529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>food_dining</td>\n",
       "      <td>74.90</td>\n",
       "      <td>43.3526</td>\n",
       "      <td>-102.5411</td>\n",
       "      <td>1126</td>\n",
       "      <td>42.788940</td>\n",
       "      <td>-103.241160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>food_dining</td>\n",
       "      <td>4.30</td>\n",
       "      <td>45.8433</td>\n",
       "      <td>-113.8748</td>\n",
       "      <td>218</td>\n",
       "      <td>46.565983</td>\n",
       "      <td>-114.186110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category     amt      lat      long  city_pop  merch_lat  \\\n",
       "0             misc_net    4.97  36.0788  -81.1781      3495  36.011293   \n",
       "1          grocery_pos  107.23  48.8878 -118.2105       149  49.159047   \n",
       "2        entertainment  220.11  42.1808 -112.2620      4154  43.150704   \n",
       "3        gas_transport   45.00  46.2306 -112.1138      1939  47.034331   \n",
       "4             misc_pos   41.96  38.4207  -79.4629        99  38.674999   \n",
       "...                ...     ...      ...       ...       ...        ...   \n",
       "1296670  entertainment   15.56  37.7175 -112.4777       258  36.841266   \n",
       "1296671    food_dining   51.70  39.2667  -77.5101       100  38.906881   \n",
       "1296672    food_dining  105.93  32.9396 -105.8189       899  33.619513   \n",
       "1296673    food_dining   74.90  43.3526 -102.5411      1126  42.788940   \n",
       "1296674    food_dining    4.30  45.8433 -113.8748       218  46.565983   \n",
       "\n",
       "         merch_long  is_fraud  \n",
       "0        -82.048315         0  \n",
       "1       -118.186462         0  \n",
       "2       -112.154481         0  \n",
       "3       -112.561071         0  \n",
       "4        -78.632459         0  \n",
       "...             ...       ...  \n",
       "1296670 -111.690765         0  \n",
       "1296671  -78.246528         0  \n",
       "1296672 -105.130529         0  \n",
       "1296673 -103.241160         0  \n",
       "1296674 -114.186110         0  \n",
       "\n",
       "[1296675 rows x 8 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_0, class_count_1 = df_train['is_fraud'].value_counts()\n",
    "\n",
    "class_0 = df_train[df_train['is_fraud'] == 0]\n",
    "class_1 = df_train[df_train['is_fraud'] == 1]\n",
    "\n",
    "class_0_under = class_0.sample(class_count_1)\n",
    "df_undersampling = pd.concat([class_0_under, class_1], axis=0)\n",
    "# undersampled_trainX = test_under.drop('is_fraud', axis =1)\n",
    "# undersampled_trainy = test_under['is_fraud']\n",
    "\n",
    "class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "df_oversampling = pd.concat([class_1_over, class_0], axis=0)\n",
    "# oversampled_trainX = test_over.drop('is_fraud', axis =1)\n",
    "# oversampled_trainy = test_over['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def select_scale_features(model, n_features, df_train, df_test):\n",
    "#     df_train = df_train.astype(int)\n",
    "#     df_test = df_test.astype(int)\n",
    "#     X_train = df_train.drop('is_fraud', axis=1)\n",
    "#     y_train = df_train['is_fraud']\n",
    "#     X_test = df_test.drop('is_fraud', axis=1)\n",
    "#     y_test = df_test['is_fraud']\n",
    "\n",
    "    # NOTE: df_train IS BASICALLY df_oversampling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_train.drop('is_fraud', axis=1),df_train['is_fraud'] , train_size=0.7, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Normalize the data\n",
    "    mean = np.mean(X_train)\n",
    "    std = np.std(X_train)\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    if model != None:\n",
    "        selector = RFE(model, n_features_to_select=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = X_train[X_train.columns[selector.support_]]\n",
    "        X_test = X_test[X_test.columns[selector.support_]]\n",
    "        \n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversampling =pd.get_dummies(df_oversampling, drop_first=True)\n",
    "# df_train = pd.get_dummies(df_train, drop_first=True)\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = select_scale_features(LogisticRegression(), 10, df_oversampling, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 386399, 0: 387103})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.826728308394807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84    387103\n",
      "           1       0.88      0.76      0.81    386399\n",
      "\n",
      "    accuracy                           0.83    773502\n",
      "   macro avg       0.83      0.83      0.83    773502\n",
      "weighted avg       0.83      0.83      0.83    773502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 442157, 1: 331345})\n",
      "Counter({0: 387103, 1: 386399})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_pred))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, y_train, X_test, y_test, criterion, max_depth, min_samples_split, random_state: int = 3000):\n",
    "    clf = DecisionTreeClassifier(random_state=random_state, criterion = criterion, max_depth = max_depth,\\\n",
    "                                 min_samples_split = min_samples_split)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test, random_state: int = 3000):\n",
    "    clf = RandomForestClassifier(random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9702599346866588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97    387103\n",
      "           1       0.96      0.99      0.97    386399\n",
      "\n",
      "    accuracy                           0.97    773502\n",
      "   macro avg       0.97      0.97      0.97    773502\n",
      "weighted avg       0.97      0.97      0.97    773502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = decision_tree(X_train, y_train, X_test, y_test, \"gini\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y_pred))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(X_train, y_train, X_test,epochs, batch_size, weights, optimizer, loss, metrics):\n",
    "    model = Sequential()\n",
    "    # input/output dimensions\n",
    "    # hidden layer -- same number of hidden units as above\n",
    "    model.add(Dense(2048, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "              \n",
    "    # configure the learning process\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    weights = compute_class_weight(class_weight=\"balanced\",classes=np.unique(y_train),y=y_train)\n",
    "    class_weights = {0: weights[0], 1: weights[1]}\n",
    "#  class_weight = class_weights\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs= epochs, batch_size = batch_size, verbose=1, validation_split = 0.3, class_weight = class_weights)\n",
    "    print(model.output)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 907672 samples, validate on 389003 samples\n",
      "Epoch 1/10\n",
      "907672/907672 [==============================] - 54s 60us/step - loss: 0.3709 - accuracy: 0.9493 - val_loss: 0.2917 - val_accuracy: 0.9894\n",
      "Epoch 2/10\n",
      "907672/907672 [==============================] - 54s 59us/step - loss: 0.3621 - accuracy: 0.9784 - val_loss: 0.2903 - val_accuracy: 0.9860\n",
      "Epoch 3/10\n",
      "907672/907672 [==============================] - 54s 59us/step - loss: 0.3286 - accuracy: 0.9854 - val_loss: 0.2840 - val_accuracy: 0.9906\n",
      "Epoch 4/10\n",
      "907672/907672 [==============================] - 54s 60us/step - loss: 0.4177 - accuracy: 0.9871 - val_loss: 0.2969 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "907672/907672 [==============================] - 55s 60us/step - loss: 0.3788 - accuracy: 0.9857 - val_loss: 0.2772 - val_accuracy: 0.9914\n",
      "Epoch 6/10\n",
      "907672/907672 [==============================] - 55s 61us/step - loss: 0.3688 - accuracy: 0.9862 - val_loss: 0.2909 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "907672/907672 [==============================] - 55s 61us/step - loss: 0.3526 - accuracy: 0.9891 - val_loss: 0.2937 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "772096/907672 [========================>.....] - ETA: 7s - loss: 0.3988 - accuracy: 0.9888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-b2aecd40f028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-160-d3a46ac27e72>\u001b[0m in \u001b[0;36mffnn\u001b[0;34m(X_train, y_train, X_test, epochs, batch_size, weights, optimizer, loss, metrics)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#  class_weight = class_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     model.fit(X_train, y_train, \n\u001b[0m\u001b[1;32m     22\u001b[0m               epochs= epochs, batch_size = batch_size, verbose=1, validation_split = 0.3, class_weight = class_weights)\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;31m# Delegate logic to `fit_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         return training_arrays.fit_loop(self, fit_function, fit_inputs,\n\u001b[0m\u001b[1;32m   1228\u001b[0m                                         \u001b[0mout_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "preds = ffnn(X_train, y_train, X_test, 10, 128, 0, 'adam', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1 if pred < 0.5 else 0 for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.05      0.10    553574\n",
      "           1       0.00      0.06      0.00      2145\n",
      "\n",
      "    accuracy                           0.05    555719\n",
      "   macro avg       0.47      0.06      0.05    555719\n",
      "weighted avg       0.93      0.05      0.10    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = metrics.classification_report(y_test, t)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(t))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1 if pred < 0.5 else 0 for pred in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
