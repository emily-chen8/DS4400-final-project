{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 4400 Final Project : Credit Card Fraud Detection\n",
    "\n",
    "#### Emily Chen, Glen Damian Lim, Tara Sawhney\n",
    "\n",
    "#### Dataset : https://www.kaggle.com/datasets/kartik2112/fraud-detection\n",
    "\n",
    "#### ML models: Logistic Regression, Decision Trees, Feedforward Neural Networks, Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# ML libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "# Neural Networks libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(20,10)})\n",
    "fraud_df = pd.read_csv('fraudTrain.csv')\n",
    "fraud_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.296675e+06\n",
       "mean     7.035104e+01\n",
       "std      1.603160e+02\n",
       "min      1.000000e+00\n",
       "25%      9.650000e+00\n",
       "50%      4.752000e+01\n",
       "75%      8.314000e+01\n",
       "max      2.894890e+04\n",
       "Name: amt, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df['amt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545.9926000000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(fraud_df['amt'],99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Amount vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # amount vs fraud\n",
    "\n",
    "# # Plotting a histogram of transaction amount vs fraud\n",
    "# # Filtering the data to only include transactions with amount less than or equal to 1000\n",
    "# # Specifying 'is_fraud' column as hue to differentiate between fraudulent and non-fraudulent transactions\n",
    "# # Using 'percent' as the statistic to show the percentage of transactions in each category\n",
    "# # Specifying 'dodge' as the multiple parameter to show the histograms side-by-side\n",
    "# # Turning off the common normalization to display the raw counts\n",
    "# # Using 25 bins to display the data more clearly\n",
    "# ax=sns.histplot(x='amt',data=fraud_df[fraud_df['amt']<=1000],hue='is_fraud',stat='percent',multiple='dodge',common_norm=False,bins=25)\n",
    "# ax.set_title('Transaction Amount vs Fraud', fontsize=14)\n",
    "# ax.set_ylabel('Percentage in Each Type')\n",
    "# ax.set_xlabel('Transaction Amount in USD')\n",
    "# plt.legend(labels=['Fraud', 'Not Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While normal transactions tend to be around 200 or less, fraud transactions are typically peak around 300 as well as 800-1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot gender vs fraud \n",
    "\n",
    "# # Plotting a histogram of gender vs fraud\n",
    "# # Specifying the 'gender' column as the x-axis and the 'is_fraud' column as the hue to differentiate between fraudulent and non-fraudulent transactions\n",
    "# # Using 'percent' as the statistic to show the percentage of transactions in each category\n",
    "# # Specifying 'dodge' as the multiple parameter to show the histograms side-by-side\n",
    "# # Turning off the common normalization to display the raw counts\n",
    "# ax = sns.histplot(x=fraud_df['gender'], data=fraud_df, hue=fraud_df['is_fraud'], \n",
    "#                   stat='percent', multiple='dodge', common_norm=False)\n",
    "\n",
    "# ax.set_title(\"Gender vs Fraud\", fontsize=14)\n",
    "# ax.set_xlabel(\"Gender\")\n",
    "# ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "# plt.legend(labels=['Fraud', 'Non-Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no clear difference between genders when it comes to fraud vs non-fraud transactions. According to the figure about, both males and females are equally prone to fraud transaction and gender is not an indicative amount of fraud transaction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spending Category vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculating the percentage difference between fraudulent and non-fraudulent transactions in each spending category\n",
    "# #filtering the data to only include non-fraudulent transactions, then counting the percentage of transactions in each spending category\n",
    "# spending_cat_1 = fraud_df[fraud_df['is_fraud'] == 0]['category'].value_counts(normalize=True).to_frame().reset_index()\n",
    "# spending_cat_1.columns = ['Category', 'Non-Fraud Percentage']\n",
    "\n",
    "# #filtering the data to only include fraudulent transactions, then counting the percentage of transactions in each spending category\n",
    "# spending_cat_2 = fraud_df[fraud_df['is_fraud'] == 1]['category'].value_counts(normalize=True).to_frame().reset_index()\n",
    "# spending_cat_2.columns = ['Category', 'Fraud Percentage']\n",
    "\n",
    "# #merging the two dataframes on the 'Category' column\n",
    "# merge = spending_cat_1.merge(spending_cat_2, on='Category')\n",
    "\n",
    "# #adding a column to the merged dataframe that calculates the percentage difference between the fraudulent and non-fraudulent transactions in each spending category\n",
    "# merge['diff'] = merge['Fraud Percentage'] - merge['Non-Fraud Percentage']\n",
    "\n",
    "# #plotting a bar chart of the percentage difference of fraudulent over non-fraudulent transactions in each spending category\n",
    "# #sorting the data by the 'diff' column in descending order\n",
    "# fig = sns.barplot(y='Category', x='diff', data=merge.sort_values('diff', ascending=False))\n",
    "\n",
    "# #adding labels to the plot\n",
    "# fig.set_xlabel('Percentage Difference')\n",
    "# fig.set_ylabel('Transaction Category')\n",
    "# plt.title('Percent Difference of Fraudulent over Non-Fraudulent Transactions in Each Spending Category', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categories have more fraudulent transactions than others. These tend to be Shopping, Groceries, and Miscellaneous. Home, Kids/Pets tend to have more normal transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculating the age of each customer by subtracting their year of birth from the current year\n",
    "# fraud_df['age'] = dt.date.today().year - pd.to_datetime(fraud_df['dob']).dt.year\n",
    "\n",
    "# #plotting a kernel density estimate (KDE) plot of the age distribution of fraudulent and non-fraudulent transactions\n",
    "# #using 'age' as the x-axis and the 'is_fraud' column as the hue to differentiate between fraudulent and non-fraudulent transactions\n",
    "# #setting 'linewidth' to 5 for a thicker line\n",
    "# #turning off the common normalization to display the raw counts\n",
    "# fig = sns.kdeplot(x=fraud_df['age'], data=fraud_df, hue=fraud_df['is_fraud'], linewidth=5, common_norm=False)\n",
    "\n",
    "# #adding labels to the plot\n",
    "# fig.set_xlabel('Age')\n",
    "# fig.set_ylabel('Density')\n",
    "\n",
    "# #setting the x-axis tick marks to show every 5 years\n",
    "# plt.xticks(np.arange(0, 110, 5))\n",
    "\n",
    "# #adding a title and legend to the plot\n",
    "# plt.title('Age Distribution in Fraud vs Non-Fraud Transactions', fontsize=14)\n",
    "# plt.legend(title='Type', labels=['Fraud', 'Not Fraud'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the figure above, normal transactions are highest at ages 37-38 and 49-50, whereas fraud transactions are smoother, second peak includes a bigger group (ages 50-65). This indicated that older people are more likely to be subject to fraud transactions than younger people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #constructing the age-transaction count distribution\n",
    "# age = fraud_df[['age','trans_num']].groupby(['age']).count().reset_index()\n",
    "# age.columns = ['age', 'age_count']\n",
    "\n",
    "# #creating the age-fraud distribution\n",
    "# fraud_age = fraud_df[['age', 'trans_num', 'is_fraud']].groupby(['age','is_fraud']).count().reset_index()\n",
    "# fraud_age.columns = ['age', 'is_fraud', 'Transaction Count']\n",
    "\n",
    "# fraud_age = fraud_age.merge(age[['age', 'age_count']], how='inner', on='age')\n",
    "\n",
    "# fraud_age['Transaction percentage'] = (fraud_age['Transaction Count']/fraud_age['age_count'])*100\n",
    "\n",
    "# fraud_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bar chart that depicts the same information as the line chart above, however this just shows the entire age distribution. \n",
    "\n",
    "# sns.barplot(data=fraud_age, y='Transaction Count', x='age', hue='is_fraud')\n",
    "# plt.title('Age Distribution and Fraud vs Non-Fraud Transactions')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HOURLY \n",
    "# #extracting the hour component from the transaction timestamp\n",
    "# fraud_df['hour'] = pd.to_datetime(fraud_df['trans_date_trans_time']).dt.hour\n",
    "\n",
    "# #plotting a histogram of the hourly distribution of fraudulent and non-fraudulent transactions\n",
    "# #using 'hour' as the x-axis and the 'is_fraud' column as the hue to differentiate between fraudulent and non-fraudulent transactions\n",
    "# #setting 'common_norm' to False to display the raw counts\n",
    "# #setting 'stat' to 'percent' to display the percentage of transactions for each hour\n",
    "# #setting 'multiple' to 'dodge' to show the two bars side-by-side\n",
    "# fig = sns.histplot(data=fraud_df, x=fraud_df['hour'], hue=fraud_df['is_fraud'], common_norm=False, \n",
    "#                    stat='percent', multiple='dodge')\n",
    "\n",
    "# #adding labels to the plot\n",
    "# fig.set_xlabel('Hour')\n",
    "# fig.set_ylabel('Percentage')\n",
    "# plt.title('Hour vs Fraud and Non-Fraud Transactions')\n",
    "\n",
    "# #setting the x-axis tick marks to show every hour\n",
    "# plt.xticks(np.arange(0, 24, 1))\n",
    "\n",
    "# #adding a legend to the plot\n",
    "# plt.legend(labels=['Fraud', 'Non-Fraud'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### WEEKLY \n",
    "# fraud_df['day'] = pd.to_datetime(fraud_df['trans_date_trans_time']).dt.dayofweek\n",
    "\n",
    "# fig = sns.histplot(data=fraud_df, x=fraud_df['day'], hue=fraud_df['is_fraud'], common_norm=False, stat='percent', multiple='dodge')\n",
    "\n",
    "# fig.set_xticklabels(['',\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"])\n",
    "\n",
    "# fig.set_xlabel('Day of the Week')\n",
    "# fig.set_ylabel('Percentage')\n",
    "\n",
    "# plt.title('Day of Week and Fraud vs Non-Fraud Transactions')\n",
    "# plt.legend(labels=['Fraud', 'Non-Fraud'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Normal transactions happen more on Sunday and Monday and fraud transactions tend to be spread out during the  week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## MONTHLY \n",
    "# #month vs fraud\n",
    "# fraud_df['month']=pd.to_datetime(fraud_df['trans_date_trans_time']).dt.month\n",
    "# fig=sns.histplot(data=fraud_df, x=fraud_df[\"month\"], hue=fraud_df[\"is_fraud\"], common_norm=False,stat='percent',multiple='dodge')\n",
    "# fig.set_xlabel('Month')\n",
    "# fig.set_ylabel('Percentage')\n",
    "# plt.title('Month and Fraud vs Non-Fraud Transactions')\n",
    "# plt.xticks(np.arange(1,13,1))\n",
    "# ax.set_xticklabels([\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",'Aug','Sep','Oct','Nov','Dec'])\n",
    "# plt.legend(labels=['Fraud', 'Not Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal payments are highest around holiday season (December) and sprign/summer, whereas fraud transactions are more concentrated in Jan-May"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State vs Fraud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate the percentage difference of fraudulent vs non-fraudulent transactions in each state\n",
    "# state_1=fraud_df['state'][fraud_df.is_fraud==0].value_counts(normalize=True)\n",
    "# state_1=state_1.to_frame()\n",
    "# state_1=state_1.reset_index()\n",
    "# state_1.columns = ['State', 'Percentage']\n",
    "\n",
    "# state_2=fraud_df['state'][fraud_df.is_fraud==1].value_counts(normalize=True)\n",
    "# state_2=state_2.to_frame()\n",
    "# state_2=state_2.reset_index()\n",
    "# state_2.columns = ['State', 'Percentage']\n",
    "\n",
    "# merge_cols=state_1.merge(state_2,on='State')\n",
    "# merge_cols['diff']=merge_cols['Percentage_y']-merge_cols['Percentage_x']\n",
    "# merge_cols['diff']=merge_cols['diff']*100\n",
    "# merge_cols=merge_cols.sort_values('diff',ascending=False)\n",
    "\n",
    "# #creat bar chart depicting state transactions\n",
    "# fig = sns.barplot(data=merge_cols, x='diff', y='State')\n",
    "# fig.set_xlabel('Percentage Difference')\n",
    "# fig.set_ylabel('State')\n",
    "# plt.title('Percent of Fraud vs Non-Fraud Transactions in Each State')\n",
    "# plt.legend(labels=['Fraud', 'Non-Fraud'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, NY and OH  higher percentage of fraudulent transactions than normal ones, while TX and MT are the opposite. However, it should be pointed out that the percentage differences in those states are not very significant but a correlation does exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fetching top 20 jobs with high transaction frequencies\n",
    "# high_trans_jobs = fraud_df['job'].value_counts().head(20).index.tolist()\n",
    "# print(high_trans_jobs)\n",
    "# job_plot = sns.countplot(fraud_df[fraud_df['job'].isin(high_trans_jobs)].job)\n",
    "# job_plot.set_xticklabels(job_plot.get_xticklabels(), rotation=90)\n",
    "# plt.title(\"Job and Fraud vs Non-Fraud Transactions\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #constructing the zip-transaction count distribution\n",
    "# job = fraud_df[['job','trans_num']].groupby(['job']).count().reset_index()\n",
    "# job.columns = ['job', 'job_count']\n",
    "\n",
    "# #creating the zip-fraud distribution\n",
    "# fraud_job = fraud_df[['job', 'trans_num', 'is_fraud']].groupby(['job','is_fraud']).count().reset_index()\n",
    "# fraud_job.columns = ['job', 'is_fraud', 'Transaction count']\n",
    "\n",
    "# fraud_job = fraud_job.merge(job[['job', 'job_count']], how='inner', on='job')\n",
    "\n",
    "# fraud_job['Transaction percentage'] = (fraud_job['Transaction count']/fraud_job['job_count'])*100\n",
    "\n",
    "# #viewing the top 30 jobs with high fraudulent transaction volumes\n",
    "# fraud_job[fraud_job['is_fraud'] == 1].sort_values(by = ['Transaction percentage'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting the fraudulent transactions percentage by binning\n",
    "# job_plot = sns.countplot(pd.cut(fraud_job[fraud_job.is_fraud == 1]['Transaction percentage'], bins = 2))\n",
    "# job_plot.set_xticklabels(job_plot.get_xticklabels(), rotation = 90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #job with more than one percent fraudulent transactions\n",
    "# fraud_job.loc[(fraud_job.is_fraud == 1) & (fraud_job['Transaction percentage'] >= 50)].job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the jobs where in high transaction frequencies have been noted.\n",
    "In the above dataframe, the transactions containing the job feature value as-Armed forces technical officer; Engineer, site; Information officer; Legal secretary; Industrial buyer; Careers adviser; Homeopath; Broadcast journalist; Personnel officer; Forest/woodland manager; Sales promotion account executive; Air traffic controller; Contracting civil engineer; Ship broker; Solicitor;2 Accountant, chartered; Dancer; Warehouse manager; Veterinary surgeon have completely fraudulent transactions\n",
    "\n",
    "The people in the jobs with high number of fraudulent transactions can be alerted about the credit card transaction frauds so that they can be more carefull while using their credit cards.\n",
    "the jobs roles in which almost all transactions are fraudulent might mean that there is some fault with the datapoint. That is, the person representing the specific job might be at fault since it is highly unlikely that all the transactions made by a person from a spceific job are fraudulent. Hence, doing some kind of background check upon the credit card user might help in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('fraudTrain.csv')\n",
    "df_test = pd.read_csv('fraudTest.csv')\n",
    "\n",
    "def datetime_column(df, col_name: str, hour: bool =False, new_col_prefix: str =''):\n",
    "    df[col_name] = pd.to_datetime(df[col_name])\n",
    "\n",
    "    if hour:\n",
    "        new_col = new_col_prefix + '_hour'\n",
    "        df[new_col] = df[col_name].dt.hour\n",
    "    df[new_col_prefix + '_weekday'] = df[col_name].dt.weekday\n",
    "    df[new_col_prefix + '_month'] = df[col_name].dt.strftime(\"%m\")\n",
    "    df[new_col_prefix + '_year'] = df[col_name].dt.year\n",
    "\n",
    "# deriving additonal columns from 'trans_date_trans_time' and 'dob' columns\n",
    "datetime_column(df_train, 'trans_date_trans_time', True, 'trans')\n",
    "datetime_column(df_test, 'trans_date_trans_time', True, 'trans')\n",
    "datetime_column(df_train, 'dob', new_col_prefix='dob')\n",
    "datetime_column(df_test, 'dob', new_col_prefix='dob')\n",
    "\n",
    "\n",
    "# dropping irrelevant columns\n",
    "df_train.drop(['gender','city','state','job','unix_time','Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "df_test.drop(['gender','city','state','job','unix_time','Unnamed: 0','cc_num','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "# Convert categorical columns\n",
    "categorical_column_names = ['category']\n",
    "\n",
    "for cat_name in categorical_column_names:\n",
    "    df_train[cat_name] = pd.factorize(df_train[cat_name])[0]\n",
    "    df_test[cat_name] = pd.factorize(df_test[cat_name])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(df):\n",
    "    class_count_0, class_count_1 = df['is_fraud'].value_counts()\n",
    "\n",
    "    class_0 = df[df['is_fraud'] == 0]\n",
    "    class_1 = df[df['is_fraud'] == 1]\n",
    "\n",
    "    class_0_under = class_0.sample(class_count_1)\n",
    "    df_undersampling = pd.concat([class_0_under, class_1], axis=0)\n",
    "\n",
    "    class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "    df_oversampling = pd.concat([class_1_over, class_0], axis=0)\n",
    "    return df_undersampling, df_oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_scale_features(model, n_features, df_train, df_test):\n",
    "    X_train = df_train.drop('is_fraud', axis=1).astype(int)\n",
    "    y_train = df_train['is_fraud'].astype(int)\n",
    "    X_test = df_test.drop('is_fraud', axis=1).astype(int)\n",
    "    y_test = df_test['is_fraud'].astype(int)\n",
    "    \n",
    "    # Normalize and scale the data\n",
    "    mean = np.mean(X_train)\n",
    "    std = np.std(X_train)\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    if model != None:\n",
    "        selector = RFE(model, n_features_to_select=n_features)\n",
    "        selector.fit(X_train, y_train)\n",
    "        X_train = X_train[X_train.columns[selector.support_]]\n",
    "        X_test = X_test[X_test.columns[selector.support_]]\n",
    "        \n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the training data\n",
    "df_undersampling, df_oversampling = resampling(df_train)\n",
    "# df_oversampling = pd.get_dummies(df_oversampling, drop_first=True)\n",
    "# df_undersampling = pd.get_dummies(df_undersampling, drop_first=True)\n",
    "# df_test = pd.get_dummies(df_test, drop_first=True)\n",
    "# df_train = pd.get_dummies(df_train, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "UNDERSAMPLING DATA:\n",
      "accuracy: 0.9732598669471442\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    553574\n",
      "           1       0.10      0.70      0.17      2145\n",
      "\n",
      "    accuracy                           0.97    555719\n",
      "   macro avg       0.55      0.84      0.58    555719\n",
      "weighted avg       1.00      0.97      0.98    555719\n",
      "\n",
      "OVERSAMPLING DATA:\n",
      "accuracy: 0.9727596141215255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    553574\n",
      "           1       0.09      0.69      0.16      2145\n",
      "\n",
      "    accuracy                           0.97    555719\n",
      "   macro avg       0.55      0.83      0.58    555719\n",
      "weighted avg       1.00      0.97      0.98    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression\\n')\n",
    "\n",
    "print('UNDERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(LogisticRegression(), 10, df_undersampling, df_test)\n",
    "y_pred = logistic_regression(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('OVERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(LogisticRegression(), 10, df_oversampling, df_test)\n",
    "y_pred = logistic_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, y_train, X_test, y_test, criterion, max_depth, min_samples_split):\n",
    "    clf = DecisionTreeClassifier(criterion = criterion, max_depth = max_depth,\\\n",
    "                                 min_samples_split = min_samples_split)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees\n",
      "\n",
      "UNDERSAMPLING DATA:\n",
      "accuracy: 0.923551291210126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    553574\n",
      "           1       0.01      0.11      0.01      2145\n",
      "\n",
      "    accuracy                           0.92    555719\n",
      "   macro avg       0.50      0.52      0.49    555719\n",
      "weighted avg       0.99      0.92      0.96    555719\n",
      "\n",
      "OVERSAMPLING DATA:\n",
      "accuracy: 0.9563358459941085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    553574\n",
      "           1       0.01      0.07      0.01      2145\n",
      "\n",
      "    accuracy                           0.96    555719\n",
      "   macro avg       0.50      0.52      0.50    555719\n",
      "weighted avg       0.99      0.96      0.97    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Decision Trees\\n')\n",
    "\n",
    "print('UNDERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(DecisionTreeClassifier(), 10, df_undersampling, df_test)\n",
    "y_pred = decision_tree(X_train, y_train, X_test, y_test, 'gini', 20, 5)\n",
    "\n",
    "print('OVERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(DecisionTreeClassifier(), 10, df_oversampling, df_test)\n",
    "y_pred = decision_tree(X_train, y_train, X_test, y_test, 'gini', 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "\n",
      "UNDERSAMPLING DATA:\n",
      "accuracy: 0.9686082354571285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    553574\n",
      "           1       0.04      0.30      0.07      2145\n",
      "\n",
      "    accuracy                           0.97    555719\n",
      "   macro avg       0.52      0.64      0.53    555719\n",
      "weighted avg       0.99      0.97      0.98    555719\n",
      "\n",
      "OVERSAMPLING DATA:\n",
      "accuracy: 0.992073332025718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.06      0.07      0.06      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.53      0.53      0.53    555719\n",
      "weighted avg       0.99      0.99      0.99    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest\\n')\n",
    "\n",
    "print('UNDERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(DecisionTreeClassifier(), 10, df_undersampling, df_test)\n",
    "y_pred = random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('OVERSAMPLING DATA:')\n",
    "X_train, y_train, X_test, y_test = select_scale_features(DecisionTreeClassifier(), 10, df_oversampling, df_test)\n",
    "y_pred = random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(X_train, y_train, X_test,epochs, batch_size, weighted, optimizer, loss, metrics):\n",
    "    model = Sequential()\n",
    "    # input/output dimensions\n",
    "    # hidden layer -- same number of hidden units as above\n",
    "    model.add(Dense(128, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "              \n",
    "    # configure the learning process\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    # Weighted class\n",
    "    if weighted:\n",
    "        weights = compute_class_weight(class_weight=\"balanced\",classes=np.unique(y_train),y=y_train)\n",
    "        class_weights = {0: weights[0], 1: weights[1]}\n",
    "        model.fit(X_train, y_train, \n",
    "                  epochs= epochs, batch_size = batch_size, verbose=1, validation_split = 0.2, class_weight = class_weights)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, \n",
    "                  epochs= epochs, batch_size = batch_size, verbose=1, validation_split = 0.2)\n",
    "        \n",
    "    print(model.output)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12009 samples, validate on 3003 samples\n",
      "Epoch 1/10\n",
      "12009/12009 [==============================] - 1s 53us/step - loss: 0.4472 - accuracy: 0.8035 - val_loss: 1.8119 - val_accuracy: 0.4998\n",
      "Epoch 2/10\n",
      "12009/12009 [==============================] - 0s 29us/step - loss: 0.3322 - accuracy: 0.8668 - val_loss: 1.8947 - val_accuracy: 0.5162\n",
      "Epoch 3/10\n",
      "12009/12009 [==============================] - 0s 26us/step - loss: 0.3069 - accuracy: 0.8743 - val_loss: 2.2102 - val_accuracy: 0.4945\n",
      "Epoch 4/10\n",
      "12009/12009 [==============================] - 0s 27us/step - loss: 0.2901 - accuracy: 0.8805 - val_loss: 2.5692 - val_accuracy: 0.4835\n",
      "Epoch 5/10\n",
      "12009/12009 [==============================] - 0s 25us/step - loss: 0.2786 - accuracy: 0.8830 - val_loss: 2.5564 - val_accuracy: 0.4562\n",
      "Epoch 6/10\n",
      "12009/12009 [==============================] - 0s 24us/step - loss: 0.2723 - accuracy: 0.8859 - val_loss: 2.9136 - val_accuracy: 0.4389\n",
      "Epoch 7/10\n",
      "12009/12009 [==============================] - 0s 24us/step - loss: 0.2648 - accuracy: 0.8872 - val_loss: 3.0322 - val_accuracy: 0.4246\n",
      "Epoch 8/10\n",
      "12009/12009 [==============================] - 0s 27us/step - loss: 0.2536 - accuracy: 0.8911 - val_loss: 3.2261 - val_accuracy: 0.4166\n",
      "Epoch 9/10\n",
      "12009/12009 [==============================] - 0s 30us/step - loss: 0.2495 - accuracy: 0.8932 - val_loss: 3.8147 - val_accuracy: 0.3164\n",
      "Epoch 10/10\n",
      "12009/12009 [==============================] - 0s 28us/step - loss: 0.2423 - accuracy: 0.9002 - val_loss: 4.0137 - val_accuracy: 0.3024\n",
      "Tensor(\"dense_24/Sigmoid:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "X_train, y_train, X_test, y_test = select_scale_features(None, 10, df_undersampling, df_test)\n",
    "undersampling_preds = ffnn(X_train, y_train, X_test, 10, 128, False, 'adam', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2062670 samples, validate on 515668 samples\n",
      "Epoch 1/10\n",
      "2062670/2062670 [==============================] - 58s 28us/step - loss: 0.1321 - accuracy: 0.9462 - val_loss: 30.7666 - val_accuracy: 0.0952\n",
      "Epoch 2/10\n",
      "2062670/2062670 [==============================] - 56s 27us/step - loss: 0.0785 - accuracy: 0.9693 - val_loss: 47.5139 - val_accuracy: 0.0820\n",
      "Epoch 3/10\n",
      "2062670/2062670 [==============================] - 59s 29us/step - loss: 0.0661 - accuracy: 0.9749 - val_loss: 48.5673 - val_accuracy: 0.0950\n",
      "Epoch 4/10\n",
      "2062670/2062670 [==============================] - 61s 29us/step - loss: 0.0597 - accuracy: 0.9777 - val_loss: 62.1235 - val_accuracy: 0.0773\n",
      "Epoch 5/10\n",
      "2062670/2062670 [==============================] - 58s 28us/step - loss: 0.0556 - accuracy: 0.9795 - val_loss: 63.9823 - val_accuracy: 0.0956\n",
      "Epoch 6/10\n",
      "2062670/2062670 [==============================] - 59s 29us/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 70.2001 - val_accuracy: 0.0931\n",
      "Epoch 7/10\n",
      "2062670/2062670 [==============================] - 59s 29us/step - loss: 0.0502 - accuracy: 0.9818 - val_loss: 59.9401 - val_accuracy: 0.0984\n",
      "Epoch 8/10\n",
      "2062670/2062670 [==============================] - 58s 28us/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 68.7337 - val_accuracy: 0.0950\n",
      "Epoch 9/10\n",
      "2062670/2062670 [==============================] - 59s 29us/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 79.8245 - val_accuracy: 0.0925\n",
      "Epoch 10/10\n",
      "2062670/2062670 [==============================] - 58s 28us/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 76.6316 - val_accuracy: 0.0939\n",
      "Tensor(\"dense_28/Sigmoid:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "X_train, y_train, X_test, y_test = select_scale_features(None, 10, df_oversampling, df_test)\n",
    "oversampling_preds = ffnn(X_train, y_train, X_test, 10, 128, False, 'adam', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1037340 samples, validate on 259335 samples\n",
      "Epoch 1/10\n",
      "1037340/1037340 [==============================] - 29s 28us/step - loss: 0.3634 - accuracy: 0.9254 - val_loss: 0.2874 - val_accuracy: 0.9346\n",
      "Epoch 2/10\n",
      "1037340/1037340 [==============================] - 29s 28us/step - loss: 0.2779 - accuracy: 0.9176 - val_loss: 0.2526 - val_accuracy: 0.8944\n",
      "Epoch 3/10\n",
      "1037340/1037340 [==============================] - 31s 30us/step - loss: 0.2491 - accuracy: 0.9200 - val_loss: 0.2334 - val_accuracy: 0.9325\n",
      "Epoch 4/10\n",
      "1037340/1037340 [==============================] - 28s 27us/step - loss: 0.2238 - accuracy: 0.9283 - val_loss: 0.2772 - val_accuracy: 0.9587\n",
      "Epoch 5/10\n",
      "1037340/1037340 [==============================] - 28s 27us/step - loss: 0.2150 - accuracy: 0.9300 - val_loss: 0.2306 - val_accuracy: 0.8983\n",
      "Epoch 6/10\n",
      "1037340/1037340 [==============================] - 28s 27us/step - loss: 0.2064 - accuracy: 0.9240 - val_loss: 0.2049 - val_accuracy: 0.9535\n",
      "Epoch 7/10\n",
      "1037340/1037340 [==============================] - 30s 29us/step - loss: 0.1962 - accuracy: 0.9341 - val_loss: 0.2633 - val_accuracy: 0.9572\n",
      "Epoch 8/10\n",
      "1037340/1037340 [==============================] - 28s 27us/step - loss: 0.1898 - accuracy: 0.9365 - val_loss: 0.2670 - val_accuracy: 0.9432\n",
      "Epoch 9/10\n",
      "1037340/1037340 [==============================] - 28s 27us/step - loss: 0.1843 - accuracy: 0.9403 - val_loss: 0.2177 - val_accuracy: 0.9391\n",
      "Epoch 10/10\n",
      "1037340/1037340 [==============================] - 29s 28us/step - loss: 0.1785 - accuracy: 0.9412 - val_loss: 0.3790 - val_accuracy: 0.9537\n",
      "Tensor(\"dense_32/Sigmoid:0\", shape=(None, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Weighted class, with original non-sampled data\n",
    "X_train, y_train, X_test, y_test = select_scale_features(None, 10, df_train, df_test)\n",
    "weighted_preds = ffnn(X_train, y_train, X_test, 10, 128, True, 'adam', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward Neural Network\n",
      "\n",
      "UNDERSAMPLING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.07      0.03      0.04      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.54      0.51      0.52    555719\n",
      "weighted avg       0.99      0.99      0.99    555719\n",
      "\n",
      "OVERSAMPLING DATA:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00    553574\n",
      "           1       0.00      1.00      0.01      2145\n",
      "\n",
      "    accuracy                           0.00    555719\n",
      "   macro avg       0.50      0.50      0.00    555719\n",
      "weighted avg       1.00      0.00      0.00    555719\n",
      "\n",
      "ORIGINAL DATA w/ weighted weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    553574\n",
      "           1       0.05      0.29      0.09      2145\n",
      "\n",
      "    accuracy                           0.98    555719\n",
      "   macro avg       0.53      0.63      0.54    555719\n",
      "weighted avg       0.99      0.98      0.99    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics for FFNN\n",
    "print('Feedforward Neural Network\\n')\n",
    "\n",
    "print('UNDERSAMPLING DATA:')\n",
    "preds = [1 if pred > 0.5 else 0 for pred in undersampling_preds]\n",
    "m = metrics.classification_report(y_test, preds)\n",
    "print(m)\n",
    "\n",
    "print('OVERSAMPLING DATA:')\n",
    "preds = [1 if pred > 0.5 else 0 for pred in oversampling_preds]\n",
    "m = metrics.classification_report(y_test, preds)\n",
    "print(m)\n",
    "\n",
    "print('ORIGINAL DATA w/ weighted weights:')\n",
    "preds = [1 if pred > 0.5 else 0 for pred in weighted_preds]\n",
    "m = metrics.classification_report(y_test, preds)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_fit(estimator, params, scoring='accuracy', cv=5):\n",
    "    best_params = GridSearchCV(estimator,\n",
    "                      param_grid=params,\n",
    "                      scoring=scoring,\n",
    "                      cv=cv)\n",
    "    best_params.fit(X_train, y_train)\n",
    "    print('best parameters:', best_params.best_params_)\n",
    "    print('accuracy:', best_params.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/shared/centos7/anaconda3/2021.07-TF/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'tol': [0.001, 0.0001, 0.00001],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "best_params = GridSearchCV(lr,\n",
    "                  param_grid=lr_params,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5)\n",
    "best_params.fit(X_train, y_train)\n",
    "print('best parameters:', best_params.best_params_)\n",
    "print('accuracy:', best_params.score())\n",
    "param_fit(lr, lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_params = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 6, 10]\n",
    "# }\n",
    "# dtc = DecisionTreeClassifier()\n",
    "# param_fit(dtc, dt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "# mlp_params = {\n",
    "#     'hidden_layer_sizes': [(10,), (30,), (50,)],\n",
    "#     'activation': ['relu', 'tanh'],\n",
    "#     'solver':['adam',\"rmsprop\"]\n",
    "#     'alpha': [0.001, 0.01, 0.1],\n",
    "# }\n",
    "\n",
    "# mlp = MLPClassifier(max_iter = 10)\n",
    "\n",
    "# param_fit(mlp, mlp_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
