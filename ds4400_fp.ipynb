{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 4400 Final Project : Credit Card Fraud Detection\n",
    "\n",
    "#### Emily Chen, Glen Damian Lim, Tara Sawhney\n",
    "\n",
    "#### Dataset : https://www.kaggle.com/datasets/kartik2112/fraud-detection\n",
    "\n",
    "#### ML models: Logistic Regression, Decision Trees, Feedforward Neural Networks, Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 21:32:02.912393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# ML libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Neural Networks libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/fraudTrain.csv')\n",
    "df_test = pd.read_csv('data/fraudTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_column(df, col_name: str, hour: bool =False, new_col_prefix: str =''):\n",
    "    df[col_name] = pd.to_datetime(df[col_name])\n",
    "\n",
    "    if hour:\n",
    "        new_col = new_col_prefix + '_hour'\n",
    "        df[new_col] = df[col_name].dt.hour\n",
    "    df[new_col_prefix + '_weekday'] = df[col_name].dt.weekday\n",
    "    df[new_col_prefix + '_month'] = df[col_name].dt.strftime(\"%m\")\n",
    "    df[new_col_prefix + '_year'] = df[col_name].dt.year\n",
    "\n",
    "# deriving additonal columns from 'trans_date_trans_time' and 'dob' columns\n",
    "datetime_column(df_train, 'trans_date_trans_time', True, 'trans')\n",
    "datetime_column(df_test, 'trans_date_trans_time', True, 'trans')\n",
    "datetime_column(df_train, 'dob', new_col_prefix='dob')\n",
    "datetime_column(df_test, 'dob', new_col_prefix='dob')\n",
    "\n",
    "\n",
    "# dropping irrelevant columns\n",
    "df_train.drop(['Unnamed: 0','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "df_test.drop(['Unnamed: 0','merchant', 'first', 'last','street','zip', 'dob', 'trans_num', 'trans_date_trans_time'], axis=1, inplace=True)\n",
    "\n",
    "# Convert categorical columns\n",
    "categorical_column_names = ['gender', 'city', 'state', 'job', 'category']\n",
    "\n",
    "for cat_name in categorical_column_names:\n",
    "    df_train[cat_name] = pd.factorize(df_train[cat_name])[0]\n",
    "    df_test[cat_name] = pd.factorize(df_test[cat_name])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_0, class_count_1 = df_train['is_fraud'].value_counts()\n",
    "\n",
    "class_0 = df_train[df_train['is_fraud'] == 0]\n",
    "class_1 = df_train[df_train['is_fraud'] == 1]\n",
    "\n",
    "class_0_under = class_0.sample(class_count_1)\n",
    "df_undersampling = pd.concat([class_0_under, class_1], axis=0)\n",
    "# undersampled_trainX = test_under.drop('is_fraud', axis =1)\n",
    "# undersampled_trainy = test_under['is_fraud']\n",
    "\n",
    "class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "df_oversampling = pd.concat([class_1_over, class_0], axis=0)\n",
    "# oversampled_trainX = test_over.drop('is_fraud', axis =1)\n",
    "# oversampled_trainy = test_over['is_fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def select_scale_features(model, n_features, df_train, df_test):\n",
    "    X_train = df_train.drop('is_fraud', axis=1)\n",
    "    y_train = df_train['is_fraud']\n",
    "    X_test = df_test.drop('is_fraud', axis=1)\n",
    "    y_test = df_test['is_fraud']\n",
    "    \n",
    "    selector = RFE(model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    X_train = X_train[X_train.columns[selector.support_]]\n",
    "    X_test = X_test[X_test.columns[selector.support_]]\n",
    "\n",
    "    # Scale training data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = select_scale_features(LogisticRegression(), 10, df_undersampling, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test, random_state: int = 3000):\n",
    "    clf = LogisticRegression(random_state=random_state, penalty=\"l2\").fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.973087117769952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    553574\n",
      "           1       0.09      0.69      0.16      2145\n",
      "\n",
      "    accuracy                           0.97    555719\n",
      "   macro avg       0.55      0.83      0.58    555719\n",
      "weighted avg       1.00      0.97      0.98    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 539962, 1: 15757})\n",
      "Counter({0: 553574, 1: 2145})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_pred))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, y_train, X_test, y_test, criterion, max_depth, min_samples_split, random_state: int = 3000):\n",
    "    clf = DecisionTreeClassifier(random_state=random_state, criterion = criterion, max_depth = max_depth,\\\n",
    "                                 min_samples_split = min_samples_split)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.classification_report(y_test,\n",
    "                                    y_pred))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9105411188028482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    553574\n",
      "           1       0.01      0.13      0.01      2145\n",
      "\n",
      "    accuracy                           0.91    555719\n",
      "   macro avg       0.50      0.52      0.48    555719\n",
      "weighted avg       0.99      0.91      0.95    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = decision_tree(X_train, y_train, X_test, y_test, \"gini\", 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 507578, 1: 48141})\n",
      "Counter({0: 553574, 1: 2145})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_pred))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(X_train, y_train, X_test,epochs, batch_size, optimizer, loss, metrics):\n",
    "    model = Sequential()\n",
    "    # input/output dimensions\n",
    "    # hidden layer -- same number of hidden units as above\n",
    "    model.add(Dense(1024, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "              \n",
    "    # configure the learning process\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    print(model.output)\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs= epochs, batch_size = batch_size, verbose=1, validation_split = 0.2)\n",
    "    print(model.output)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_31/Sigmoid:0', description=\"created by layer 'dense_31'\")\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:16:18.523559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:16:23.575778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 6s 49ms/step - loss: 0.3100 - accuracy: 0.8641 - val_loss: 2.7422 - val_accuracy: 0.4226\n",
      "Epoch 2/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2410 - accuracy: 0.8946 - val_loss: 6.3626 - val_accuracy: 0.1878\n",
      "Epoch 3/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.2143 - accuracy: 0.9071 - val_loss: 13.3875 - val_accuracy: 0.0922\n",
      "Epoch 4/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1901 - accuracy: 0.9191 - val_loss: 16.0969 - val_accuracy: 0.1495\n",
      "Epoch 5/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1791 - accuracy: 0.9258 - val_loss: 17.9990 - val_accuracy: 0.1702\n",
      "Epoch 6/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.1616 - accuracy: 0.9317 - val_loss: 20.5791 - val_accuracy: 0.1702\n",
      "Epoch 7/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.1584 - accuracy: 0.9342 - val_loss: 22.6373 - val_accuracy: 0.1622\n",
      "Epoch 8/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.1457 - accuracy: 0.9395 - val_loss: 23.3486 - val_accuracy: 0.1841\n",
      "Epoch 9/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.1386 - accuracy: 0.9423 - val_loss: 31.5661 - val_accuracy: 0.1239\n",
      "Epoch 10/25\n",
      "94/94 [==============================] - 4s 40ms/step - loss: 0.1377 - accuracy: 0.9420 - val_loss: 32.9417 - val_accuracy: 0.1149\n",
      "Epoch 11/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1316 - accuracy: 0.9451 - val_loss: 30.1782 - val_accuracy: 0.1692\n",
      "Epoch 12/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1272 - accuracy: 0.9475 - val_loss: 33.9240 - val_accuracy: 0.1345\n",
      "Epoch 13/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1181 - accuracy: 0.9512 - val_loss: 35.8622 - val_accuracy: 0.1625\n",
      "Epoch 14/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1192 - accuracy: 0.9520 - val_loss: 36.6490 - val_accuracy: 0.1409\n",
      "Epoch 15/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1122 - accuracy: 0.9536 - val_loss: 40.9465 - val_accuracy: 0.1499\n",
      "Epoch 16/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1116 - accuracy: 0.9559 - val_loss: 43.9149 - val_accuracy: 0.1289\n",
      "Epoch 17/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1150 - accuracy: 0.9555 - val_loss: 40.1584 - val_accuracy: 0.1605\n",
      "Epoch 18/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1028 - accuracy: 0.9601 - val_loss: 46.1147 - val_accuracy: 0.1225\n",
      "Epoch 19/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.1021 - accuracy: 0.9602 - val_loss: 50.6421 - val_accuracy: 0.1159\n",
      "Epoch 20/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.1031 - accuracy: 0.9589 - val_loss: 46.6933 - val_accuracy: 0.1382\n",
      "Epoch 21/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.0974 - accuracy: 0.9632 - val_loss: 47.0299 - val_accuracy: 0.1439\n",
      "Epoch 22/25\n",
      "94/94 [==============================] - 4s 42ms/step - loss: 0.0907 - accuracy: 0.9645 - val_loss: 50.1458 - val_accuracy: 0.1545\n",
      "Epoch 23/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.0908 - accuracy: 0.9651 - val_loss: 46.7684 - val_accuracy: 0.1702\n",
      "Epoch 24/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.0886 - accuracy: 0.9652 - val_loss: 49.1719 - val_accuracy: 0.1568\n",
      "Epoch 25/25\n",
      "94/94 [==============================] - 4s 41ms/step - loss: 0.0866 - accuracy: 0.9654 - val_loss: 43.3092 - val_accuracy: 0.1838\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_31/Sigmoid:0', description=\"created by layer 'dense_31'\")\n",
      "   30/17367 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:17:57.007606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17367/17367 [==============================] - 57s 3ms/step\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "preds = ffnn(X_train, y_train, X_test, 25, 128, 'adam', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.00      0.00      0.00      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.50      0.50      0.50    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glendamianlim/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/glendamianlim/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/glendamianlim/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "a = metrics.classification_report(y_test, t)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1 for pred in preds if pred > 0.5]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
